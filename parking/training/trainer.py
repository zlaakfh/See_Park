import torch
import numpy as np
import matplotlib.pyplot as plt
from torch.amp import autocast
from sklearn.metrics import precision_score, recall_score, confusion_matrix, f1_score

# ===============================================================================================================
def eval_one_epoch(model, loader, criterion_reg, criterion_cls, device):
    model.eval()

    total_loss_sum = 0.0
    total_reg_loss_sum = 0.0  # [ì¶”ê°€] Reg Loss ë”°ë¡œ ì§‘ê³„
    total_cls_loss_sum = 0.0  # [ì¶”ê°€] Cls Loss ë”°ë¡œ ì§‘ê³„
    
    abs_err_lin = 0.0
    abs_err_ang = 0.0
    
    # [ì¶”ê°€] Scatter Plotì„ ìœ„í•œ ë¦¬ìŠ¤íŠ¸ë“¤
    all_preds_lin = []
    all_targets_lin = []
    all_preds_ang = []
    all_targets_ang = []
    
    # Classificationìš©
    all_preds_cls = []
    all_targets_cls = []
    
    n = 0

    with torch.no_grad():
        for images, reg_labels, cls_labels in loader:
            images = images.to(device, non_blocking=True)
            reg_labels = reg_labels.to(device, non_blocking=True)
            cls_labels = cls_labels.to(device, non_blocking=True)

            outputs = model(images)
            pred_reg = outputs['control']
            pred_cls = outputs['class']
            
            # Loss ê³„ì‚°
            loss_reg = criterion_reg(pred_reg, reg_labels)
            loss_cls = criterion_cls(pred_cls, cls_labels)
            loss = loss_reg + loss_cls
            
            bs = reg_labels.size(0)
            n += bs
            
            # Sum Updates
            total_loss_sum += loss.item() * bs
            total_reg_loss_sum += loss_reg.item() * bs # [ì¶”ê°€]
            total_cls_loss_sum += loss_cls.item() * bs # [ì¶”ê°€]

            # MAE Calculation
            abs_err_lin += torch.abs(pred_reg[:, 0] - reg_labels[:, 0]).sum().item()
            abs_err_ang += torch.abs(pred_reg[:, 1] - reg_labels[:, 1]).sum().item()
            
            # --- ë°ì´í„° ìˆ˜ì§‘ (CPUë¡œ ì´ë™) ---
            # 1. Regression (Linear & Angular)
            all_preds_lin.extend(pred_reg[:, 0].cpu().numpy())
            all_targets_lin.extend(reg_labels[:, 0].cpu().numpy())
            
            all_preds_ang.extend(pred_reg[:, 1].cpu().numpy())
            all_targets_ang.extend(reg_labels[:, 1].cpu().numpy())

            # 2. Classification
            _, predicted_class = torch.max(pred_cls, 1)
            all_preds_cls.extend(predicted_class.cpu().numpy())
            all_targets_cls.extend(cls_labels.cpu().numpy())

    # í‰ê·  ê³„ì‚°
    avg_loss = total_loss_sum / n
    avg_reg_loss = total_reg_loss_sum / n  # [ì¶”ê°€]
    avg_cls_loss = total_cls_loss_sum / n  # [ì¶”ê°€]
    
    lin_mae  = abs_err_lin / n
    ang_mae  = abs_err_ang / n

    # Metrics
    accuracy = np.mean(np.array(all_preds_cls) == np.array(all_targets_cls)) * 100.0
    precision = precision_score(all_targets_cls, all_preds_cls, average='macro', zero_division=0)
    recall = recall_score(all_targets_cls, all_preds_cls, average='macro', zero_division=0)
    f1 = f1_score(all_targets_cls, all_preds_cls, average='macro', zero_division=0)
    
    conf_matrix = confusion_matrix(all_targets_cls, all_preds_cls)
    
    class_accs = (conf_matrix.diagonal() / (conf_matrix.sum(axis=1) + 1e-6)) * 100.0
    class_accs = class_accs.tolist()

    # [ë°˜í™˜ê°’ ëŒ€í­ ì¶”ê°€]
    # Loss 3ì¢…ë¥˜, MAE 2ì¢…ë¥˜, Clsì§€í‘œë“¤, ê·¸ë¦¬ê³  Scatterìš© ë¦¬ìŠ¤íŠ¸ë“¤
    return (avg_loss, avg_reg_loss, avg_cls_loss, 
            lin_mae, ang_mae, 
            accuracy, class_accs, precision, recall, f1, conf_matrix,
            all_targets_lin, all_preds_lin, all_targets_ang, all_preds_ang)

# ===============================================================================================================

def get_lr(optimizer):
    for param_group in optimizer.param_groups:
        return param_group['lr']

def train_one_epoch(model, loader, criterion_reg, criterion_cls, optimizer, device, scaler, scheduler=None, is_onecycle=False):
    model.train()
    total_loss_sum = 0.0
    reg_loss_sum = 0.0
    cls_loss_sum = 0.0
    
    for images, reg_labels, cls_labels in loader:
        images = images.to(device, non_blocking=True)
        reg_labels = reg_labels.to(device, non_blocking=True)
        cls_labels = cls_labels.to(device, non_blocking=True)

        optimizer.zero_grad()

        with autocast("cuda"):
            outputs = model(images)
            pred_reg = outputs['control']
            pred_cls = outputs['class']

            loss_reg = criterion_reg(pred_reg, reg_labels)
            loss_cls = criterion_cls(pred_cls, cls_labels)
            loss = loss_reg + loss_cls

        scaler.scale(loss).backward()
        scaler.unscale_(optimizer)
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0) 
        scaler.step(optimizer)
        scaler.update()

        if is_onecycle and scheduler:
            scheduler.step()

        bs = images.size(0)
        total_loss_sum += loss.item() * bs
        reg_loss_sum += loss_reg.item() * bs
        cls_loss_sum += loss_cls.item() * bs

    dataset_len = len(loader.dataset)
    return (total_loss_sum / dataset_len), (reg_loss_sum / dataset_len), (cls_loss_sum / dataset_len)

def check_sampler_balance(loader):
    """
    WeightedRandomSamplerê°€ ì˜ ì ìš©ë˜ì—ˆëŠ”ì§€ ì²« ë°°ì¹˜ë§Œ í™•ì¸í•˜ëŠ” í•¨ìˆ˜
    """
    print("\nğŸ” [Check] Verifying WeightedRandomSampler...")
    try:
        # ì²« ë²ˆì§¸ ë°°ì¹˜ë§Œ ê°€ì ¸ì™€ë´„ (DataLoaderê°€ iterableì´ë¯€ë¡œ iter() ì‚¬ìš©)
        temp_batch = next(iter(loader))
        _, _, temp_cls_labels = temp_batch
        
        temp_labels = temp_cls_labels.numpy()
        unique, counts = np.unique(temp_labels, return_counts=True)
        count_dict = dict(zip(unique, counts))
        
        print(f"   >> Batch Size: {len(temp_labels)}")
        print(f"   >> Class Counts in Batch: {count_dict}")
        
        total = len(temp_labels)
        ratio_0 = count_dict.get(0, 0) / total * 100
        ratio_1 = count_dict.get(1, 0) / total * 100
        print(f"   >> Ratio -> Drive(0): {ratio_0:.1f}% | Stop(1): {ratio_1:.1f}%")

        if abs(ratio_0 - ratio_1) < 20: # ì°¨ì´ê°€ 20%p ì´ë‚´ë©´ ê· í˜• ì¡íŒ ê±¸ë¡œ ê°„ì£¼
            print("   âœ… Sampler seems to be WORKING! (Balanced)")
        else:
            print("   âš ï¸ WARNING: NOT balanced. Check Sampler code.")
    except Exception as e:
        print(f"   âš ï¸ Error checking sampler: {e}")
    print("=" * 60)

def plot_confusion_matrix(cm, class_names):
    """
    Confusion Matrix(numpy array)ë¥¼ ë°›ì•„ì„œ matplotlib Figure ê°ì²´ë¡œ ë³€í™˜
    """
    figure = plt.figure(figsize=(8, 8))
    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title("Confusion Matrix")
    plt.colorbar()
    
    tick_marks = np.arange(len(class_names))
    plt.xticks(tick_marks, class_names, rotation=45)
    plt.yticks(tick_marks, class_names)

    # ë§¤íŠ¸ë¦­ìŠ¤ ì•ˆì— ìˆ«ì í…ìŠ¤íŠ¸ ë„£ê¸° (ë°°ê²½ìƒ‰ì— ë”°ë¼ ê¸€ììƒ‰ ë³€ê²½)
    threshold = cm.max() / 2.
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            color = "white" if cm[i, j] > threshold else "black"
            plt.text(j, i, format(cm[i, j], 'd'), 
                     horizontalalignment="center", color=color)
            
    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    
    return figure

def plot_regression_scatter(targets, preds, title="Regression Analysis"):
    """
    xì¶•: ì •ë‹µ(Ground Truth), yì¶•: ì˜ˆì¸¡(Prediction)
    ì´ìƒì ì¸ ê²½ìš° y=x ì„  ìœ„ì— ì ë“¤ì´ ëª¨ì—¬ì•¼ í•¨.
    """
    fig, ax = plt.subplots(figsize=(6, 6))
    ax.scatter(targets, preds, alpha=0.5, s=10)
    
    # y=x ê¸°ì¤€ì„  (ì™„ë²½í•œ ì˜ˆì¸¡ì„ )
    lims = [
        np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes
        np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes
    ]
    ax.plot(lims, lims, 'r-', alpha=0.75, zorder=0)
    
    ax.set_aspect('equal')
    ax.set_xlim(lims)
    ax.set_ylim(lims)
    ax.set_xlabel('Ground Truth')
    ax.set_ylabel('Prediction')
    ax.set_title(title)
    ax.grid(True)
    return fig